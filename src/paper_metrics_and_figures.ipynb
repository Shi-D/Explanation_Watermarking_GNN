{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27437fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from   embed_and_verify import *\n",
    "from   config import *\n",
    "from   prune_and_fine_tune_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import networkx as nx\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import requests\n",
    "from matplotlib import patches, transforms\n",
    "\n",
    "from   scipy import stats\n",
    "from   scipy.stats import norm, anderson, kstest, zscore, shapiro\n",
    "\n",
    "import torch\n",
    "from   torch.nn import ModuleList\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from   torch_geometric.datasets import Reddit2\n",
    "from   torch_geometric.nn import GATConv, GCNConv, GraphConv, SAGEConv, GINConv, global_mean_pool\n",
    "from   torch_geometric.transforms import RandomLinkSplit\n",
    "from   torch_geometric.data import Data\n",
    "from   torch_geometric.loader import DataLoader\n",
    "\n",
    "import zipfile\n",
    "\n",
    "from   pcgrad.pcgrad import PCGrad \n",
    "\n",
    "mpl.rcParams['figure.dpi']=250\n",
    "\n",
    "root_folder = '<path_to_repo_dir'\n",
    "training_folder = os.path.join(root_folder,'training_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c61e470",
   "metadata": {},
   "source": [
    "# Results Printouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f850491",
   "metadata": {},
   "source": [
    "### Classification Only (No Watermarking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda19e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy rates without watermarking\n",
    "\n",
    "# Examples of results you may want to display:\n",
    "photo_sage_results_clf_only =  training_folder + '/photo/clf_only_archSAGE_elu_nLayers3_hDim256_drop0.1_skipTrue/clf_only_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300'\n",
    "photo_gcn_results_clf_only =  training_folder + '/photo/clf_only_archGCN_elu_nLayers3_hDim256_drop0.1_skipTrue/clf_only_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300'\n",
    "photo_sgc_results_clf_only =  training_folder + '/photo/clf_only_archSGC_elu_nLayers3_hDim256_drop0.1_skipTrue/clf_only_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300'\n",
    "CS_sage_results_clf_only = training_folder + '/CS/clf_only_archSAGE_elu_nLayers3_hDim256_drop0.1_skipTrue/clf_only_nodeDropP0.1_nodeMixUp5_edgeDrop0.1_lr0.001_epochs90'\n",
    "CS_gcn_results_clf_only = training_folder + '/CS/clf_only_archGCN_elu_nLayers3_hDim256_drop0.1_skipTrue/clf_only_nodeDropP0.1_nodeMixUp5_edgeDrop0.1_lr0.001_epochs90'\n",
    "CS_sgc_results_clf_only = training_folder + '/CS/clf_only_archSGC_elu_nLayers3_hDim256_drop0.1_skipTrue/clf_only_nodeDropP0.1_nodeMixUp5_edgeDrop0.1_lr0.001_epochs90'\n",
    "pubmed_sage_results_clf_only = training_folder + '/PubMed/clf_only_archSAGE_elu_nLayers3_hDim512_drop0.95_skipTrue/clf_only_nodeDropP0.1_nodeMixUp0.6_edgeDrop0.1_lr0.005_epochs200'\n",
    "pubmed_gcn_results_clf_only = training_folder + '/PubMed/clf_only_archGCN_elu_nLayers3_hDim512_drop0.8_skipTrue/clf_only_nodeDropP0.1_nodeMixUp0.6_edgeDrop0.1_lr0.005_epochs200'\n",
    "pubmed_sgc_results_clf_only = training_folder + '/PubMed/clf_only_archSGC_elu_nLayers3_hDim512_drop0.8_skipTrue/clf_only_nodeDropP0.1_nodeMixUp0.6_edgeDrop0.1_lr0.005_epochs200'\n",
    "\n",
    "results_folders = [photo_sage_results_clf_only, photo_gcn_results_clf_only, photo_sgc_results_clf_only, \n",
    "                   CS_sage_results_clf_only, CS_gcn_results_clf_only, CS_sgc_results_clf_only,\n",
    "                   pubmed_sage_results_clf_only,pubmed_gcn_results_clf_only,pubmed_sgc_results_clf_only]\n",
    "\n",
    "result_names = ['Photo SAGE', 'Photo GCN', 'Photo SGC', \n",
    "                'CS SAGE', 'CS GCN','CS SGC', \n",
    "                'PubMed SAGE', 'PubMed GCN', 'PubMed SGC']\n",
    "\n",
    "\n",
    "print(\"Accuracy without watermarking\")\n",
    "for results_folder,results_name in zip(results_folders,result_names):\n",
    "    # if 'SAGE' in results_name:\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    test_accs = []\n",
    "    seeds = [f for f in os.listdir(results_folder) if 'seed' in f and f!='seed0']\n",
    "    for s in seeds:\n",
    "        file = results_folder + '/' + s + '/results_clf_only.txt'\n",
    "        with open(file,'r') as f:\n",
    "            lines = f.readlines()\n",
    "        f.close()\n",
    "        train_acc = float(lines[1].split(\"(trn/val/test)= \")[1].split('/')[0])\n",
    "        val_acc = float(lines[1].split(\"(trn/val/test)= \")[1].split('/')[1])\n",
    "        test_acc = float(lines[1].split(\"(trn/val/test)= \")[1].split('/')[2])\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        test_accs.append(test_acc)\n",
    "    print(f'{f\"{results_name}:\".ljust(11)} average train/val/test acc = {np.mean(train_accs):.3f}/{np.mean(val_accs):.3f}/{np.mean(test_accs):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376209e",
   "metadata": {},
   "source": [
    "### Random Backdoor Watermark (Not our method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d03ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WATERMARK RANDOM BACKDOOR\n",
    "alpha=0.4\n",
    "\n",
    "# Examples of results you may want to display:\n",
    "photo_sage_random_backdoor  = training_folder + f'/photo/watermark_random_backdoor_archSAGE_elu_nLayers3_hDim256_drop0.1_skipTruepEdge0.05_pOnes0.5_dataProportion0.05_alpha{alpha}/watermark_random_backdoor_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300_pcgrad'\n",
    "photo_gcn_random_backdoor  = training_folder + f'/photo/watermark_random_backdoor_archGCN_elu_nLayers3_hDim256_drop0.1_skipTruepEdge0.05_pOnes0.5_dataProportion0.05_alpha{alpha}/watermark_random_backdoor_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300_pcgrad'\n",
    "photo_sgc_random_backdoor  = training_folder + f'/photo/watermark_random_backdoor_archSGC_elu_nLayers3_hDim256_drop0.1_skipTruepEdge0.05_pOnes0.5_dataProportion0.05_alpha{alpha}/watermark_random_backdoor_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300_pcgrad'\n",
    "CS_sage_random_backdoor            = training_folder + f'/CS/watermark_random_backdoor_archSAGE_elu_nLayers3_hDim256_drop0.1_skipTruepEdge0.05_pOnes0.5_dataProportion0.05_alpha{alpha}/watermark_random_backdoor_nodeDropP0.1_nodeMixUp5_edgeDrop0.1_lr0.001_epochs90_pcgrad'\n",
    "CS_gcn_random_backdoor            = training_folder + f'/CS/watermark_random_backdoor_archGCN_elu_nLayers3_hDim256_drop0.1_skipTruepEdge0.05_pOnes0.5_dataProportion0.05_alpha{alpha}/watermark_random_backdoor_nodeDropP0.1_nodeMixUp5_edgeDrop0.1_lr0.001_epochs90_pcgrad'\n",
    "CS_sgc_random_backdoor            = training_folder + f'/CS/watermark_random_backdoor_archSGC_elu_nLayers3_hDim256_drop0.1_skipTruepEdge0.05_pOnes0.5_dataProportion0.05_alpha{alpha}/watermark_random_backdoor_nodeDropP0.1_nodeMixUp5_edgeDrop0.1_lr0.001_epochs90_pcgrad'\n",
    "pubmed_sage_random_backdoor        = training_folder + f'/PubMed/watermark_random_backdoor_archSAGE_elu_nLayers3_hDim512_drop0.95_skipTruepEdge0.05_pOnes0.5_dataProportion0.05_alpha{alpha}/watermark_random_backdoor_nodeDropP0.1_nodeMixUp0.6_edgeDrop0.1_lr0.005_epochs200_pcgrad'\n",
    "pubmed_gcn_random_backdoor        = training_folder + f'/PubMed/watermark_random_backdoor_archGCN_elu_nLayers3_hDim512_drop0.95_skipTruepEdge0.05_pOnes0.5_dataProportion0.05_alpha{alpha}/watermark_random_backdoor_nodeDropP0.1_nodeMixUp0.6_edgeDrop0.1_lr0.005_epochs200_pcgrad'\n",
    "pubmed_sgc_random_backdoor        = training_folder + f'/PubMed/watermark_random_backdoor_archSGC_elu_nLayers3_hDim512_drop0.95_skipTruepEdge0.05_pOnes0.5_dataProportion0.05_alpha{alpha}/watermark_random_backdoor_nodeDropP0.1_nodeMixUp0.6_edgeDrop0.1_lr0.005_epochs200_pcgrad'\n",
    "\n",
    "result_names = ['Photo SAGE', 'Photo GCN', 'Photo SGC', \n",
    "                'CS SAGE', 'CS GCN', 'CS SGC', \n",
    "                'PubMed SAGE','PubMed GCN','PubMed SGC']\n",
    "\n",
    "results_folders = [photo_sage_random_backdoor,photo_gcn_random_backdoor, photo_sgc_random_backdoor,\n",
    "                   CS_sage_random_backdoor,CS_gcn_random_backdoor, CS_sgc_random_backdoor,\n",
    "                   pubmed_sage_random_backdoor,pubmed_gcn_random_backdoor,pubmed_sgc_random_backdoor]\n",
    "\n",
    "print(\"Watermark random backdoor\")\n",
    "for results_folder,results_name in zip(results_folders,result_names):\n",
    "    if 'SAGE' in results_name:\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        test_accs = []\n",
    "        trigger_accs = []\n",
    "        seeds = [f for f in os.listdir(results_folder) if 'seed' in f and f!='seed0']\n",
    "        for s in seeds:\n",
    "            file = results_folder + '/' + s + '/results_watermark_random_backdoor.txt'\n",
    "            with open(file,'r') as f:\n",
    "                lines = f.readlines()\n",
    "            f.close()\n",
    "            train_acc = float(lines[1].split(\"(trn/val/test)= \")[1].split('/')[0])\n",
    "            val_acc = float(lines[1].split(\"(trn/val/test)= \")[1].split('/')[1])\n",
    "            test_acc = float(lines[1].split(\"(trn/val/test)= \")[1].split('/')[2].split(', ')[0])\n",
    "            trigger_acc = float(lines[1].split(\"trigger acc = \")[1].split('/')[0].split('\\n')[0])\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "            test_accs.append(test_acc)\n",
    "            trigger_accs.append(trigger_acc)\n",
    "        print(f'{f\"{results_name}:\".ljust(11)} average train/val/test acc = {np.mean(train_accs):.3f}/{np.mean(val_accs):.3f}/{np.mean(test_accs):.3f}, average trigger acc = {np.mean(trigger_accs):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ee4bc4",
   "metadata": {},
   "source": [
    "### Graphlime Backdoor Watermark (Not our method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a67e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WATERMARK GRAPHLIME BACKDOOR\n",
    "\n",
    "# Examples of results you may want to display:\n",
    "target_label=0\n",
    "photo_sage_graphlime_backdoor  = training_folder + f'/photo/watermark_graphlime_backdoor_archSAGE_elu_nLayers3_hDim256_drop0.1_skipTruetargetLabel{target_label}_poisonRate0.05_watermarkSize0.2/watermark_graphlime_backdoor_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300_pcgrad'\n",
    "photo_gcn_graphlime_backdoor   = training_folder + f'/photo/watermark_graphlime_backdoor_archGCN_elu_nLayers3_hDim256_drop0.1_skipTruetargetLabel{target_label}_poisonRate0.05_watermarkSize0.2/watermark_graphlime_backdoor_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300_pcgrad'\n",
    "photo_sgc_graphlime_backdoor   = training_folder + f'/photo/watermark_graphlime_backdoor_archSGC_elu_nLayers3_hDim256_drop0.1_skipTruetargetLabel{target_label}_poisonRate0.05_watermarkSize0.2/watermark_graphlime_backdoor_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300_pcgrad'\n",
    "CS_sage_graphlime_backdoor     = training_folder + f'/CS/watermark_graphlime_backdoor_archSAGE_elu_nLayers3_hDim256_drop0.1_skipTruetargetLabel{target_label}_poisonRate0.05_watermarkSize0.2/watermark_graphlime_backdoor_nodeDropP0.1_nodeMixUp5_edgeDrop0.1_lr0.001_epochs90_pcgrad'\n",
    "CS_gcn_graphlime_backdoor      = training_folder + f'/CS/watermark_graphlime_backdoor_archGCN_elu_nLayers3_hDim256_drop0.1_skipTruetargetLabel{target_label}_poisonRate0.05_watermarkSize0.2/watermark_graphlime_backdoor_nodeDropP0.1_nodeMixUp5_edgeDrop0.1_lr0.001_epochs90_pcgrad'\n",
    "CS_sgc_graphlime_backdoor      = training_folder + f'/CS/watermark_graphlime_backdoor_archSGC_elu_nLayers3_hDim256_drop0.1_skipTruetargetLabel{target_label}_poisonRate0.05_watermarkSize0.2/watermark_graphlime_backdoor_nodeDropP0.1_nodeMixUp5_edgeDrop0.1_lr0.001_epochs90_pcgrad'\n",
    "pubmed_sage_graphlime_backdoor = training_folder + f'/PubMed/watermark_graphlime_backdoor_archSAGE_elu_nLayers3_hDim512_drop0.95_skipTruetargetLabel{target_label}_poisonRate0.05_watermarkSize0.2/watermark_graphlime_backdoor_nodeDropP0.1_nodeMixUp0.6_edgeDrop0.1_lr0.005_epochs200_pcgrad'\n",
    "pubmed_gcn_graphlime_backdoor  = training_folder + f'/PubMed/watermark_graphlime_backdoor_archGCN_elu_nLayers3_hDim512_drop0.8_skipTruetargetLabel{target_label}_poisonRate0.05_watermarkSize0.2/watermark_graphlime_backdoor_nodeDropP0.1_nodeMixUp0.6_edgeDrop0.1_lr0.005_epochs200_pcgrad'\n",
    "pubmed_sgc_graphlime_backdoor  = training_folder + f'/PubMed/watermark_graphlime_backdoor_archSGC_elu_nLayers3_hDim512_drop0.8_skipTruetargetLabel{target_label}_poisonRate0.05_watermarkSize0.2/watermark_graphlime_backdoor_nodeDropP0.1_nodeMixUp0.6_edgeDrop0.1_lr0.005_epochs200_pcgrad'\n",
    "result_names = ['Photo SAGE', 'Photo GCN', 'Photo SGC', \n",
    "                'CS SAGE', 'CS GCN', 'CS SGC', \n",
    "                'PubMed SAGE','PubMed GCN','PubMed SGC']\n",
    "results_folders = [photo_sage_graphlime_backdoor,photo_gcn_graphlime_backdoor, photo_sgc_graphlime_backdoor,\n",
    "                   CS_sage_graphlime_backdoor,CS_gcn_graphlime_backdoor, CS_sgc_graphlime_backdoor,\n",
    "                   pubmed_sage_graphlime_backdoor,pubmed_gcn_graphlime_backdoor,pubmed_sgc_graphlime_backdoor]\n",
    "print(\"Watermark graphlime backdoor\")\n",
    "for results_folder,results_name in zip(results_folders,result_names):\n",
    "    if 'SAGE' in results_name:\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        test_accs = []\n",
    "        backdoor_node_accs = []\n",
    "        seeds = [f for f in os.listdir(results_folder) if 'seed' in f and f!='seed0']\n",
    "        for s in seeds:\n",
    "            file = results_folder + '/' + s + '/results_watermark_graphlime_backdoor.txt'\n",
    "            with open(file,'r') as f:\n",
    "                lines = f.readlines()\n",
    "            f.close()\n",
    "            train_acc = float(lines[1].split(\"(trn/val/test)= \")[1].split('/')[0])\n",
    "            val_acc = float(lines[1].split(\"(trn/val/test)= \")[1].split('/')[1])\n",
    "            test_acc = float(lines[1].split(\"(trn/val/test)= \")[1].split('/')[2].split(', ')[0])\n",
    "            backdoor_node_acc = float(lines[1].split(\"backdoor nodes acc = \")[1].split('/')[0].split('\\n')[0])\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "            test_accs.append(test_acc)\n",
    "            backdoor_node_accs.append(backdoor_node_acc)\n",
    "        print(f'{f\"{results_name}:\".ljust(11)} average train/val/test acc = {np.mean(train_accs):.3f}/{np.mean(val_accs):.3f}/{np.mean(test_accs):.3f}, backdoor_node_acc = {np.mean(backdoor_node_accs):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da3da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_printout_for_subgraph_size(num_subgraph, subgraph_size, train_acc, val_acc, match_rate, p_val):\n",
    "    avg_p_val_str = '<0.001' if p_val<0.001 else f'{p_val:.3f}'\n",
    "    ret_str = f'{num_subgraph} SUBGRAPHS, SIZE {subgraph_size}:'\n",
    "    ret_str += '\\n   ACC_TRN/ACC_VAL'.ljust(25) + 'MATCH_RATE'.ljust(14) + 'P-VAL'\n",
    "    ret_str += f'\\n   {100*train_acc:.1f}/{100*val_acc:.1f}'.ljust(25) + f'{match_rate:.1f}'.ljust(14) + avg_p_val_str\n",
    "    print(ret_str)\n",
    "\n",
    "def get_latex_str_for_subgraph_size(train_acc, val_acc, match_rate, p_val):\n",
    "    avg_p_val_str = '<0.001' if p_val<0.001 else f'{p_val:.3f}'\n",
    "    return f'{100*train_acc:.1f}/{100*val_acc:.1f} & {match_rate:.1f} & {avg_p_val_str}'\n",
    "\n",
    "\n",
    "\n",
    "# results_paths = [\n",
    "# f'{training_folder}/photo/clf_only_archSAGE_elu_nLayers3_hDim256_drop0.1_skipTrue/clf_only_nodeDropP0.3_nodeMixUp1_nodeFeatMask0.3_edgeDrop0.3_lr0.0002_epochs300/seed0/results_clf_only.txt'\n",
    "# ,\n",
    "# f'{training_folder}/computers/clf_only_archGCN_elu_nLayers3_hDim256_drop0.1_skipTrue/seed0'\n",
    "# ,\n",
    "# f'{training_folder}/PubMed/clf_only_archSAGE_elu_nLayers3_hDim256_drop0.1_skipTrue/seed0'\\\n",
    "# ,\n",
    "# f'{training_folder}/CS/clf_only_archSAGE_elu_nLayers3_hDim256_drop0.1_skipTrue/seed0'\\\n",
    "# ]\n",
    "\n",
    "# # plot=True\n",
    "# # for results_path in results_paths:\n",
    "# #     dataset_name = (results_path.split('training_results')[1]).split('/')[0]\n",
    "# #     lines = open(results_path,'r').readlines()\n",
    "# #     print('dataset_name:',dataset_name)\n",
    "# #     print(lines)\n",
    "# #     size_lines = lines[1::2]\n",
    "# #     value_lines = [v[:-1] if v[-1:]=='\\n' else v for v in lines[2::2]]\n",
    "# #     sizes = [int((line.split('(')[1]).split(' ')[0]) for line in size_lines]\n",
    "# #     ps = [[float(entry.split(':')[1]) for entry in value.split(',')] for value in value_lines]\n",
    "# #     sizes_sorted, ps_sorted = zip(*sorted(list(zip(sizes,ps))))\n",
    "# #     size_p_dict = dict(zip(sizes_sorted,ps_sorted))\n",
    "\n",
    "\n",
    "\n",
    "# #     if plot==True:\n",
    "\n",
    "# #         p0s_sorted = [ps_[0] for ps_ in ps_sorted]\n",
    "# #         p1s_sorted = [ps_[1] for ps_ in ps_sorted]\n",
    "# #         pn1s_sorted = [ps_[2] for ps_ in ps_sorted]\n",
    "\n",
    "# #         plt.plot(sizes_sorted, p0s_sorted,label='p(entry==0)')\n",
    "# #         plt.plot(sizes_sorted, p1s_sorted,label='p(entry==1)')\n",
    "# #         plt.plot(sizes_sorted, pn1s_sorted,label='p(entry==-1)')\n",
    "# #         plt.xlabel('Subgraph Size (Number of Nodes)')\n",
    "# #         plt.ylabel('Probability')\n",
    "# #         plt.title(dataset_name)\n",
    "# #         plt.legend()\n",
    "# #         plt.show()\n",
    "    \n",
    "\n",
    "# with open(os.path.join(training_folder,'subgraph_size_comparison.txt'),'r') as f:\n",
    "#     subgraph_sizes = ast.literal_eval(f.readline().split('subgraph_sizes: ')[1].split('\\n')[0])\n",
    "#     train_accs_ = ast.literal_eval(f.readline().split('train_accs: ')[1].split('\\n')[0])\n",
    "#     val_accs_ = ast.literal_eval(f.readline().split('val_accs: ')[1].split('\\n')[0])\n",
    "#     match_rates_ = ast.literal_eval(f.readline().split('match_rates: ')[1].split('\\n')[0])\n",
    "#     p_vals_ = ast.literal_eval(f.readline().split('p_values: ')[1])\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acac714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_watermark_performance(dataset_name, seed, architecture_folder, num_subgraphs, subgraph_size, verification_confidence, continuation=False, starting_epoch=0, project_dir = ''):\n",
    "    \"\"\"\n",
    "    Extracts and analyzes watermarking performance from trained model results.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (str): Name of dataset (photo, CS, PubMed)\n",
    "        seed (int): Random seed identifier for specific training run\n",
    "        architecture_folder (str): Path to architecture-specific results\n",
    "        num_subgraphs (int): Number of watermarked subgraphs used in training\n",
    "        subgraph_size (float): Fraction of nodes per subgraph\n",
    "        verification_confidence (float): Statistical confidence level (e.g., 0.99)\n",
    "        continuation (bool): Whether this was continued training from checkpoint\n",
    "        starting_epoch (int): Starting epoch if continuation training\n",
    "        project_dir (str): Root project directory path\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (avg_trn_acc, avg_val_acc, avg_match_rate, avg_p_val)\n",
    "            - avg_trn_acc: Average training accuracy across seeds\n",
    "            - avg_val_acc: Average validation accuracy across seeds\n",
    "            - avg_match_rate: Average watermark feature alignment rate\n",
    "            - avg_p_val: Average p-value for watermark significance\n",
    "        \"\"\"\n",
    "    data_training_path = f'{project_dir}/training_results/{dataset_name}/'\n",
    "    if len(architecture_folder.split('/'))<3:\n",
    "        architecture_folder = os.path.join(data_training_path, architecture_folder)\n",
    "\n",
    "    train_val_test_split = [0.6,0.2,0.2]\n",
    "    dataset = prep_data(dataset_name=dataset_name, location='default', batch_size='default', transform_list='default',  train_val_test_split=train_val_test_split, verbose=False)\n",
    "    data = dataset[0]\n",
    "    get_presets(dataset,dataset_name)\n",
    "    config.subgraph_kwargs['numSubgraphs']=num_subgraphs\n",
    "    \n",
    "    def obtain_final_significance_against_empirical(Trainer_object, data, subgraph_dict_not_watermarked, mu_natural_empirical, sigma_natural_empirical):\n",
    "        watermark_loss_kwargs = config_dict['watermark_loss_kwargs']\n",
    "        optimization_kwargs = config_dict['optimization_kwargs']\n",
    "        regression_kwargs = config_dict['regression_kwargs']\n",
    "        node_classifier = Trainer_object.node_classifier\n",
    "        watermark_match_rates, acc_trn, _, acc_val, target_matches, [_, match_count_wmk_without_zeros, _, confidence_wmk_without_zeros], \\\n",
    "            [_, _, _, _] = easy_run_node_classifier(Trainer_object, node_classifier, data, mu_natural_empirical, sigma_natural_empirical, subgraph_dict, subgraph_dict_not_watermarked, watermark_loss_kwargs, optimization_kwargs, regression_kwargs, target_confidence=verification_confidence,also_show_un_watermarked_counts=False)\n",
    "        return acc_trn, acc_val, target_matches, match_count_wmk_without_zeros, confidence_wmk_without_zeros, watermark_match_rates\n",
    "    \n",
    "    model_paths = [os.path.join(architecture_folder, folder) for folder in os.listdir(architecture_folder) if folder[0]!='.' and 'ignore' not in folder]\n",
    "    model_path = [p for p in model_paths if int(p.split('numSubgraphs')[1].split('_')[0])==num_subgraphs and float(p.split('fraction')[1].split('_')[0])==subgraph_size][0]\n",
    "    assert os.path.exists(model_path)\n",
    "    seeds = [seed_name for seed_name in os.listdir(model_path) if seed_name[0]!='.' and '.png' not in seed_name and 'ignore' not in seed_name]\n",
    "    avg_acc_trn, avg_acc_val, avg_match_count_wmk_without_zeros, avg_confidence_wmk_without_zeros, avg_wmk_match_rates = [],[],[],[],[]\n",
    "    avg_p_vals = []\n",
    "    for seed in seeds:\n",
    "        full_model_path = os.path.join(model_path,seed)\n",
    "        assert os.path.exists(os.path.join(full_model_path,'config_dict'))\n",
    "        config_dict = pickle.load(open(os.path.join(full_model_path,'config_dict'),'rb'))\n",
    "        subgraph_dict_filename = 'subgraph_dict' if continuation==False else f'subgraph_dict_continuation_from_{starting_epoch}'\n",
    "        subgraph_dict = pickle.load(open(os.path.join(full_model_path,subgraph_dict_filename),'rb'))\n",
    "        Trainer_object_filename = 'Trainer' if continuation==False else f'Trainer_continuation_from_{starting_epoch}'\n",
    "        Trainer_object = pickle.load(open(os.path.join(full_model_path,Trainer_object_filename),'rb'))\n",
    "        distribution_records_filename = 'distribution.txt' if continuation==False else f'distribution_continuation_from_{starting_epoch}.txt'\n",
    "        distribution_records_file = os.path.join(full_model_path,distribution_records_filename)\n",
    "        with open(distribution_records_file,'r') as f:\n",
    "            lines = f.readlines()\n",
    "        f.close()\n",
    "        mu_natural_empirical = float(lines[1].split('mu_natural=')[1].split(',')[0])\n",
    "        sigma_natural_empirical = float(lines[1].split('sigma_natural=')[1])\n",
    "        acc_trn, acc_val, _, match_count_wmk_without_zeros, confidence_wmk_without_zeros, watermark_match_rates = obtain_final_significance_against_empirical(Trainer_object, data, None, mu_natural_empirical, sigma_natural_empirical)\n",
    "        avg_acc_trn.append(acc_trn.item())\n",
    "        avg_acc_val.append(acc_val.item())\n",
    "        avg_match_count_wmk_without_zeros.append(match_count_wmk_without_zeros)\n",
    "        avg_confidence_wmk_without_zeros.append(confidence_wmk_without_zeros)\n",
    "        avg_wmk_match_rates.append(watermark_match_rates)\n",
    "        conf = np.mean(avg_confidence_wmk_without_zeros)\n",
    "        avg_p_vals.append(1-conf)\n",
    "    \n",
    "    avg_trn_acc = np.mean(avg_acc_trn)\n",
    "    avg_val_acc = np.mean(avg_acc_val)\n",
    "    avg_match_rate = np.mean(watermark_match_rates)\n",
    "    avg_p_val = np.mean(avg_p_vals)\n",
    "    return avg_trn_acc, avg_val_acc,avg_match_rate, avg_p_val\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def ablation_plot(dataset_hyperparameter_dict, datasets=['photo','PubMed','CS'], recollect=False, arch='SAGE', num_subgraph=4,exclude_title=False, variable='subgraph_size',\n",
    "                                  xticksize=7,yticksize=7,xlabelsize=9,ylabelsize=9,smalltitlesize=11,bigtitlesize=13,legendtitlesize=7,annotatesize=7,xrotation=45, project_dir = ''):\n",
    "    \"\"\"\n",
    "    Generates ablation study plots showing performance vs hyperparameter variations.\n",
    "    \n",
    "    Args:\n",
    "        dataset_hyperparameter_dict (dict): Nested dict with dataset->architecture->hyperparameters\n",
    "        datasets (list): List of dataset names to include in plot\n",
    "        recollect (bool): Whether to recompute results or load from cache\n",
    "        arch (str): GNN architecture to analyze (SAGE, GCN, SGC)\n",
    "        num_subgraph (int): Number of subgraphs (used when variable='subgraph_size')\n",
    "        exclude_title (bool): Whether to suppress plot title\n",
    "        variable (str): Which hyperparameter to vary ('subgraph_size' or 'num_subgraph')\n",
    "        **plot_kwargs: Additional plotting parameters (font sizes, etc.)\n",
    "    \n",
    "    Output: PNG figure showing performance trends across hyperparameter space\n",
    "    \"\"\"\n",
    "    # project_dir: the folder that src, training_results, etc. are contained in\n",
    "    # dropout assumed to be 0.1 unless new / different models are added, or if the dataset is PubMed\n",
    "    # naming conventions may have shifted: nLayers vs numLayers\n",
    "\n",
    "    starting_epoch=0\n",
    "    subgraph_sizes = [0.000,0.002,0.004,0.006,0.008,0.010]\n",
    "    num_subgraphs  = [2,3,4,5]\n",
    "    num_subgraph=4\n",
    "    subgraph_size=0.005\n",
    "    fig = plt.figure(figsize=(8,1.5))\n",
    "    gs = gridspec.GridSpec(1, 5, figure=fig,width_ratios=[1,0.1,1,0.1,1])\n",
    "    for i, dataset_name in enumerate(datasets):\n",
    "        train_results_dir = os.path.join(project_dir,'training_results',dataset_name)\n",
    "        ax = fig.add_subplot(gs[0,i*2])\n",
    "\n",
    "        dropout_str = dataset_hyperparameter_dict[dataset_name][arch]['dropout_str']\n",
    "        numLayers = dataset_hyperparameter_dict[dataset_name][arch]['numLayers']\n",
    "        hDim = dataset_hyperparameter_dict[dataset_name][arch]['hDim']\n",
    "        preserve_edges_str = '_preserve_edges' if dataset_hyperparameter_dict[dataset_name][arch]['preserve_edges'] else ''\n",
    "        \n",
    "        architecture_folder = f'{train_results_dir}/arch{arch}_elu_nLayers{numLayers}_hDim{hDim}_drop{dropout_str}_skipTrue{preserve_edges_str}'\n",
    "\n",
    "        verification_confidence=0.99\n",
    "\n",
    "        if recollect==True:\n",
    "            train_accs = []\n",
    "            val_accs = []\n",
    "            match_rates = []\n",
    "            p_vals = []\n",
    "            if variable=='subgraph_size':\n",
    "                for subgraph_size in subgraph_sizes:\n",
    "                    avg_trn_acc, avg_val_acc,avg_match_rate, avg_p_val = extract_watermark_performance(dataset_name, seed, architecture_folder,num_subgraphs=num_subgraph,subgraph_size=subgraph_size,verification_confidence=verification_confidence, continuation=False,starting_epoch=starting_epoch)\n",
    "                    train_accs.append(avg_trn_acc)\n",
    "                    val_accs.append(avg_val_acc)\n",
    "                    match_rates.append(avg_match_rate)\n",
    "                    p_vals.append(avg_p_val)  \n",
    "                    get_performance_printout_for_subgraph_size(num_subgraph, subgraph_size, avg_trn_acc, avg_val_acc, avg_match_rate, avg_p_val)         \n",
    "                    latex_str = get_latex_str_for_subgraph_size(avg_trn_acc, avg_val_acc, avg_match_rate, avg_p_val)\n",
    "                    print('\\nfor latex table:')\n",
    "                    print(latex_str)\n",
    "                with open(os.path.join(train_results_dir,'subgraph_size_comparison.txt'),'w') as f:\n",
    "                    f.write(f'subgraph_sizes: {subgraph_sizes}')\n",
    "                    f.write(f'\\ntrain_accs: {train_accs}')\n",
    "                    f.write(f'\\nval_accs: {val_accs}')\n",
    "                    f.write(f'\\nmatch_rates: {match_rates}')\n",
    "                    f.write(f'\\np_values: {p_vals}')\n",
    "                f.close()\n",
    "            elif variable=='num_subgraph':\n",
    "                for num_subgraph in num_subgraphs:\n",
    "                    avg_trn_acc, avg_val_acc,avg_match_rate, avg_p_val = extract_watermark_performance(dataset_name, seed, architecture_folder,num_subgraphs=num_subgraph,subgraph_size=subgraph_size,verification_confidence=verification_confidence, continuation=False,starting_epoch=starting_epoch)\n",
    "                    train_accs.append(avg_trn_acc)\n",
    "                    val_accs.append(avg_val_acc)\n",
    "                    match_rates.append(avg_match_rate)\n",
    "                    p_vals.append(avg_p_val)  \n",
    "                    get_performance_printout_for_subgraph_size(num_subgraph, subgraph_size, avg_trn_acc, avg_val_acc, avg_match_rate, avg_p_val)         \n",
    "                    latex_str = get_latex_str_for_subgraph_size(avg_trn_acc, avg_val_acc, avg_match_rate, avg_p_val)\n",
    "                    print('\\nfor latex table:')\n",
    "                    print(latex_str)\n",
    "                with open(os.path.join(train_results_dir,'num_subgraph_comparison.txt'),'w') as f:\n",
    "                    f.write(f'num_subgraphs: {num_subgraphs}')\n",
    "                    f.write(f'\\ntrain_accs: {train_accs}')\n",
    "                    f.write(f'\\nval_accs: {val_accs}')\n",
    "                    f.write(f'\\nmatch_rates: {match_rates}')\n",
    "                    f.write(f'\\np_values: {p_vals}')\n",
    "                f.close()\n",
    "        else:\n",
    "            if variable=='subgraph_size':\n",
    "                with open(os.path.join(train_results_dir,'subgraph_size_comparison.txt'),'r') as f:\n",
    "                    subgraph_sizes = ast.literal_eval(f.readline().split('subgraph_sizes: ')[1].split('\\n')[0])\n",
    "                    train_accs = ast.literal_eval(f.readline().split('train_accs: ')[1].split('\\n')[0])\n",
    "                    val_accs = ast.literal_eval(f.readline().split('val_accs: ')[1].split('\\n')[0])\n",
    "                    match_rates = ast.literal_eval(f.readline().split('match_rates: ')[1].split('\\n')[0])\n",
    "                    p_vals = ast.literal_eval(f.readline().split('p_values: ')[1])\n",
    "                f.close()\n",
    "                for s,t,v,m,p in zip(subgraph_sizes,train_accs,val_accs,match_rates, p_vals):\n",
    "                    get_performance_printout_for_subgraph_size(num_subgraph, s, t, v, m, p)         \n",
    "                    latex_str = get_latex_str_for_subgraph_size(t, v, m, p)\n",
    "                    print('\\nfor latex table:')\n",
    "                    print(latex_str)\n",
    "            elif variable=='num_subgraph':\n",
    "                with open(os.path.join(train_results_dir,'num_subgraph_comparison.txt'),'r') as f:\n",
    "                    num_subgraphs = ast.literal_eval(f.readline().split('num_subgraphs: ')[1].split('\\n')[0])\n",
    "                    train_accs = ast.literal_eval(f.readline().split('train_accs: ')[1].split('\\n')[0])\n",
    "                    val_accs = ast.literal_eval(f.readline().split('val_accs: ')[1].split('\\n')[0])\n",
    "                    match_rates = ast.literal_eval(f.readline().split('match_rates: ')[1].split('\\n')[0])\n",
    "                    p_vals = ast.literal_eval(f.readline().split('p_values: ')[1])\n",
    "                f.close()\n",
    "                for n,t,v,m,p in zip(num_subgraphs,train_accs,val_accs,match_rates, p_vals):\n",
    "                    get_performance_printout_for_subgraph_size(n, subgraph_size, t, v, m, p)         \n",
    "                    latex_str = get_latex_str_for_subgraph_size(t, v, m, p)\n",
    "                    print('\\nfor latex table:')\n",
    "                    print(latex_str)\n",
    "\n",
    "        if variable=='num_subgraph':\n",
    "            xvals=num_subgraphs\n",
    "            default_str='Default:\\n4 Subgraphs'\n",
    "            xlabel='# Watermarked Subgraphs ($T$)'\n",
    "            default_value=4\n",
    "        elif variable=='subgraph_size':\n",
    "            xvals=subgraph_sizes\n",
    "            default_str='Default\\nsize:\\n0.005'\n",
    "            xlabel=f'Watermarked Subgraph Size ($s$)'\n",
    "            default_value=0.005\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        ax.axvline(default_value,color='black',lw=0.5)\n",
    "        ax.plot(xvals,[100*a for a in val_accs],color='blue',label='Test Acc',zorder=1) \n",
    "        ax.plot(xvals,match_rates,color='blue',linestyle='dashdot',label='Watermark Alignment',zorder=2)\n",
    "        ax2.plot(xvals,p_vals,color='red',label='$p$-value',zorder=3,alpha=0.8)\n",
    "        text_x = 0.0051 if variable=='subgraph_size' else 2.75\n",
    "        ax.text(text_x,40,default_str,color='black',fontsize=annotatesize,zorder=10,clip_on=False)\n",
    "        if variable=='subgraph_size':\n",
    "            # Define the custom tick positions and labels\n",
    "            custom_ticks = [0, 0.002,0.004,0.006,0.008,0.01]  # Fewer ticks than xvals\n",
    "            custom_labels = [\"0.000\", \"0.002\", \"0.004\", \"0.006\", \"0.008\", \"0.010\"]  # Custom labels for these ticks\n",
    "            # Apply the ticks and labels\n",
    "            ax.set_xticks(custom_ticks)  # Set the tick positions\n",
    "            ax.set_xticklabels(custom_labels, fontsize=xticksize, rotation=xrotation)  # Set the corresponding labels\n",
    "        else:\n",
    "            ax.set_xticks(xvals)\n",
    "            ax.set_xticklabels(xvals,fontsize=xticksize,rotation=xrotation)\n",
    "\n",
    "        acc_ticks = [0,20,40,60,80,100]\n",
    "        ax.set_yticks(acc_ticks)\n",
    "        ax.set_yticklabels(acc_ticks,fontsize=yticksize)\n",
    "        ax2_yticks = [0, 1e-3, 2e-3, 3e-3]\n",
    "        ax2_ytick_labels = ['0', '1e-3', '2e-3', '3e-3']\n",
    "        ax2.set_yticks(ax2_yticks)\n",
    "        ax2.set_yticklabels(ax2_ytick_labels,fontsize=yticksize)\n",
    "        ax.set_ylim(0,102)\n",
    "        ax2.set_ylim(-0.0001,0.003)\n",
    "        ax.set_ylabel('Percent',fontsize=ylabelsize,labelpad=-38)\n",
    "        ax.set_xlabel(xlabel,fontsize=xlabelsize)\n",
    "        ax2.set_ylabel('p-value',fontsize=ylabelsize,labelpad=-33,rotation=270)\n",
    "        ax.set_title(dataset_name.capitalize() if dataset_name=='photo' else dataset_name,fontsize=smalltitlesize)\n",
    "\n",
    "\n",
    "\n",
    "    ax_handles, ax_labels = ax.get_legend_handles_labels()\n",
    "    ax2_handles, ax2_labels = ax2.get_legend_handles_labels()\n",
    "    handles = ax_handles + ax2_handles\n",
    "    labels = ax_labels + ax2_labels\n",
    "    legend_y=-0.45 if variable=='subgraph_size' else -0.3\n",
    "    fig.legend(handles=handles, labels=labels, loc='center', bbox_to_anchor=(0.5, legend_y), ncol=3,fontsize=legendtitlesize)\n",
    "    if exclude_title==False:\n",
    "        fig.suptitle('Performance Metrics vs. Target Subgraph Size',y=1.1,fontsize=bigtitlesize)\n",
    "    fig.subplots_adjust(wspace=0.35)\n",
    "    plt.savefig(f'performance_vs_{variable}.png',bbox_inches='tight',dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example:\n",
    "\n",
    "seed=0\n",
    "num_subgraph=4\n",
    "arch='SAGE'\n",
    "xticksize=10#6.5\n",
    "yticksize=10#6.5\n",
    "xlabelsize=10#8\n",
    "ylabelsize=10#8\n",
    "smalltitlesize=14#11\n",
    "bigtitlesize=13\n",
    "legendtitlesize=10#7\n",
    "annotatesize=10#7\n",
    "exclude_title=True\n",
    "\n",
    "\n",
    "try:\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except:\n",
    "    current_dir = os.getcwd()\n",
    "project_dir = os.path.dirname(current_dir)    \n",
    "\n",
    "\n",
    "dataset_hyperparameter_dict = { 'photo':   {\n",
    "                                            'SAGE':             {'dropout_str': '0.1',  'numLayers': 3,     'hDim': 256,    'preserve_edges': True},\n",
    "                                            'GCN':              {'dropout_str': '0.1',  'numLayers': 3,     'hDim': 256,    'preserve_edges': False},\n",
    "                                            'SGC':              {'dropout_str': '0.1',  'numLayers': 3,     'hDim': 256,    'preserve_edges': False},\n",
    "                                            'Transformers':     {'dropout_str': '0.1',  'numLayers': 3,     'hDim': 256,    'preserve_edges': True}\n",
    "                                            },\n",
    "                                'CS':      {\n",
    "                                            'SAGE':             {'dropout_str': '0.1',  'numLayers': 3,     'hDim': 256,    'preserve_edges': True},\n",
    "                                            'GCN':              {'dropout_str': '0.1',  'numLayers': 3,     'hDim': 256,    'preserve_edges': False},\n",
    "                                            'SGC':              {'dropout_str': '0.1',  'numLayers': 3,     'hDim': 256,    'preserve_edges': False},\n",
    "                                            'Transformers':     {'dropout_str': '0.1',  'numLayers': 3,     'hDim': 256,    'preserve_edges': True}\n",
    "                                            },\n",
    "                                'PubMed':  {\n",
    "                                            'SAGE':             {'dropout_str': '0.8',  'numLayers': 3,     'hDim': 512,    'preserve_edges': False},\n",
    "                                            'GCN':              {'dropout_str': '0.95', 'numLayers': 3,     'hDim': 512,    'preserve_edges': False},\n",
    "                                            'SGC':              {'dropout_str': '0.95', 'numLayers': 3,     'hDim': 512,    'preserve_edges': False},\n",
    "                                            'Transformers':     {'dropout_str': '0.1',  'numLayers': 3,     'hDim': 256,    'preserve_edges': True}\n",
    "                                            }\n",
    "                                }\n",
    "\n",
    "\n",
    "variable='num_subgraph'\n",
    "xrotation=45 if variable=='subgraph_size' else 0\n",
    "recollect=False\n",
    "ablation_plot(dataset_hyperparameter_dict,  datasets=['photo','CS','PubMed'], recollect=recollect, arch=arch, num_subgraph=num_subgraph,exclude_title=exclude_title, variable=variable,\n",
    "                            xticksize=xticksize,yticksize=yticksize,xlabelsize=xlabelsize,ylabelsize=ylabelsize,\n",
    "                            smalltitlesize=smalltitlesize,bigtitlesize=bigtitlesize,legendtitlesize=legendtitlesize,annotatesize=annotatesize,xrotation=xrotation, project_dir=project_dir)\n",
    "variable='subgraph_size'\n",
    "xrotation=45 if variable=='subgraph_size' else 0\n",
    "recollect=False\n",
    "ablation_plot(dataset_hyperparameter_dict, datasets=['photo','CS','PubMed'], recollect=recollect, arch=arch, num_subgraph=num_subgraph,exclude_title=exclude_title, variable=variable,\n",
    "                            xticksize=xticksize,yticksize=yticksize,xlabelsize=xlabelsize,ylabelsize=ylabelsize,\n",
    "                            smalltitlesize=smalltitlesize,bigtitlesize=bigtitlesize,legendtitlesize=legendtitlesize,annotatesize=annotatesize,xrotation=xrotation, project_dir=project_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad07926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binom(n, k):\n",
    "    if k > n:\n",
    "        return 0\n",
    "    return math.comb(n, k)\n",
    "\n",
    "def probability_at_least_j_same_group(N, k, c, n_sub, j):\n",
    "    \"\"\"\n",
    "    Computes probability of problematic node overlap between watermarked subgraphs.\n",
    "    \n",
    "    Args:\n",
    "        N (int): Total number of training nodes\n",
    "        k (int): Total number of target feature positions (nodes × subgraphs)\n",
    "        c (int): Number of watermarked subgraphs (collections)\n",
    "        n_sub (int): Number of nodes per subgraph\n",
    "        j (int): Minimum overlap size to consider problematic\n",
    "    \"\"\"\n",
    "    # Each group size\n",
    "    group_size = k // c\n",
    "    total_ways = binom(N, n_sub)\n",
    "    def prob_less_than_j_from_group():\n",
    "        sum_prob = 0\n",
    "        for m in range(j):\n",
    "            sum_prob += binom(group_size, m) * binom(N - group_size, n_sub - m)\n",
    "        return sum_prob / total_ways\n",
    "    prob_no_group_j_or_more = prob_less_than_j_from_group() ** c\n",
    "    return 1 - prob_no_group_j_or_more\n",
    "\n",
    "\n",
    "def plot_overlap_probability(datasets = ['photo','PubMed','CS'], num_subgraph=4, xrotation=45,xticksize=7,yticksize=7,xlabelsize=8,ylabelsize=8,annotationsize=7,legendsize=8,legendtitlesize=8,bigtitlesize=13,smalltitlesize=11):\n",
    "\n",
    "    \"\"\"\n",
    "    Analyzes and plots theoretical probability of subgraph node overlap.\n",
    "    \n",
    "    Args:\n",
    "        datasets (list): Datasets to analyze\n",
    "        num_subgraph (int): Number of watermarked subgraphs\n",
    "        **style_kwargs: Plotting style parameters\n",
    "\n",
    "    Purpose: Validates theoretical assumptions about subgraph independence and guides hyperparameter selection to avoid problematic overlap rates\n",
    "    \"\"\"\n",
    "    subgraph_sizes = [0.001,0.002,0.003,0.004,0.005,0.006,0.007,0.008,0.009,0.01]\n",
    "    fig,axs=plt.subplots(1,3,figsize=(11,2.3))\n",
    "    for i, dataset_name in enumerate(datasets):\n",
    "        ax=axs[i]\n",
    "        dataset = prep_data(dataset_name=dataset_name, location='default', batch_size='default', transform_list='default',  train_val_test_split=[0.6,0.2,0.2], verbose=False)\n",
    "        data = dataset[0]\n",
    "        len_train = len_train=sum(data.train_mask).item()\n",
    "\n",
    "        subgraph_size_overlap_dicts={j:[] for j in [1,2,3,4,5,'n_sub']}\n",
    "        for subgraph_size in subgraph_sizes:\n",
    "            n_sub = int(subgraph_size*len_train)\n",
    "            num_target_entries=  n_sub*4\n",
    "            for j in [1,2,3,4,5,'n_sub']:\n",
    "                j_ = n_sub if j=='n_sub' else j\n",
    "                p_j_overlap = probability_at_least_j_same_group(len_train, num_target_entries, num_subgraph, n_sub, j_)\n",
    "                subgraph_size_overlap_dicts[j].append(p_j_overlap)\n",
    "        for j in [1,2,3,4,5,'n_sub']:\n",
    "            j_key = j if j!='n_sub' else 'all'\n",
    "            ax.plot(subgraph_sizes,subgraph_size_overlap_dicts[j],label=j_key)\n",
    "\n",
    "        p_intervals=[0.0,0.2,0.4,0.6,0.8,1.0]\n",
    "        ax.set_yticks(p_intervals)\n",
    "        ax.set_yticklabels(p_intervals,fontsize=yticksize)\n",
    "        ax.set_xticks(subgraph_sizes)\n",
    "        ax.set_xticklabels(subgraph_sizes,fontsize=xticksize,rotation=xrotation)\n",
    "        ax.text(0.0051,0.91,'Default Size\\n0.005',color='black',fontsize=annotationsize)\n",
    "        ax.set_ylabel(f'Probability',fontsize=ylabelsize,labelpad=1)\n",
    "        ax.set_xlabel(f'Watermarked Subgraph Size ($s$)',fontsize=xlabelsize)\n",
    "        ax.axvline(0.005,color='black',lw=0.5)\n",
    "        ax.set_ylim(-0.05,1.05)\n",
    "        ax.set_title('Photo' if dataset_name=='photo' else dataset_name,fontsize=smalltitlesize)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    legend = ax.legend(handles=handles, labels=labels, loc='center', bbox_to_anchor=(1.25, 0.5), ncol=1,fontsize=legendsize, title='# Nodes\\nOverlapping',title_fontsize=legendtitlesize)\n",
    "    legend.get_title().set_ha('center')\n",
    "    fig.subplots_adjust(wspace=0.2)\n",
    "    plt.savefig('probability_of_overlap.png',bbox_inches='tight',dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_overlap_probability(datasets=['photo','PubMed','CS'], num_subgraph=4, xrotation=45,xticksize=9,yticksize=9,xlabelsize=9,ylabelsize=9,annotationsize=8,legendsize=9,legendtitlesize=9,bigtitlesize=13,smalltitlesize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_prune_stats(model_path, confidence, pruning_type='structured',ignore_zeros=True):\n",
    "    \"\"\"\n",
    "    Extracts pruning attack results from saved experiment files.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to model results directory\n",
    "        confidence (float): Statistical confidence level for significance testing\n",
    "        pruning_type (str): Type of pruning applied ('structured' or 'unstructured')\n",
    "        ignore_zeros (bool): Whether to exclude zero-valued features from match counting\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (prune_rates, train_accs, val_accs, wmk_matches, target_matches_empirical, \n",
    "                mu_natural_empirical, sigma_natural_empirical)\n",
    "            - prune_rates: Array of pruning percentages tested\n",
    "            - train_accs, val_accs: Accuracy curves during pruning\n",
    "            - wmk_matches: Watermark match counts at each pruning level\n",
    "            - target_matches_empirical: Significance threshold for detection\n",
    "            - mu_natural_empirical, sigma_natural_empirical: Baseline distribution parameters\n",
    "    \"\"\"\n",
    "\n",
    "    assert pruning_type in ['structured','unstructured']\n",
    "    file = f'results_prune_{pruning_type}.txt'\n",
    "    dataset_name = model_path.split('training_results')[1].split('/')[1].split('/')[0]\n",
    "    all_train_accs = []\n",
    "    all_val_accs = []\n",
    "    all_wmk_matches = []\n",
    "    all_target_matches_empirical = []\n",
    "    all_mu_natural_empirical = []\n",
    "    all_sigma_natural_empirical = []\n",
    "\n",
    "    seeds = [path.split('seed')[1] for path in os.listdir(model_path) if path[0]!='.' and 'png' not in path]\n",
    "    for seed in seeds:\n",
    "        full_path = os.path.join(model_path,f'seed{seed}',file)\n",
    "        with open(full_path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "        f.close()\n",
    "        prune_rates = [float(l_.split()[0]) for l_ in [l for l in ''.join(lines).split('Prune rate: ') if len(l)>0]]\n",
    "        all_train_accs.append([float(l.split('Trn acc: ')[1].split()[0]) for l in lines[1:]])#[1::2]])\n",
    "        all_val_accs.append([float(l.split('Val acc: ')[1].split()[0]) for l in lines[1:]])#[1::2]])\n",
    "        if ignore_zeros==True:\n",
    "            all_wmk_matches.append([int(l.split('# Matches Wmk w/wout 0s:')[1].split()[0][1:-1].split(',')[1]) for l in [line for line in lines if \"# Matches\" in line]])\n",
    "        elif ignore_zeros==False:\n",
    "            all_wmk_matches.append([int(l.split('# Matches Wmk w/wout 0s:')[1].split()[0][1:-1].split(',')[0]) for l in [line for line in lines if \"# Matches\" in line]])\n",
    "        \n",
    "        mu_natural_empirical = float(''.join(open(os.path.join(model_path,f'seed{seed}','distribution.txt')).readlines()).split('mu_natural=')[1].split(',')[0])\n",
    "        sigma_natural_empirical = float(''.join(open(os.path.join(model_path,f'seed{seed}','distribution.txt')).readlines()).split('sigma_natural=')[1].split(',')[0])\n",
    "        z_t = norm.ppf(confidence)\n",
    "        all_mu_natural_empirical.append(mu_natural_empirical)\n",
    "        all_sigma_natural_empirical.append(sigma_natural_empirical)       \n",
    "        target_matches_empirical = np.ceil(min(mu_natural_empirical +z_t*sigma_natural_empirical,config.dataset_attributes[dataset_name]['num_features']))\n",
    "        all_target_matches_empirical.append(target_matches_empirical) \n",
    "\n",
    "    train_accs = torch.mean(torch.vstack([torch.tensor(l) for l in all_train_accs]),dim=0)\n",
    "    val_accs = torch.mean(torch.vstack([torch.tensor(l) for l in all_val_accs]),dim=0)\n",
    "    wmk_matches = torch.mean(torch.vstack([torch.tensor(l) for l in all_wmk_matches]),dtype=float,dim=0)\n",
    "    mu_natural_empirical = int(np.round(np.mean(all_mu_natural_empirical)))\n",
    "    sigma_natural_empirical = int(np.round(np.mean(all_sigma_natural_empirical)))\n",
    "    target_matches_empirical = int(np.round(np.mean(all_target_matches_empirical)))\n",
    "\n",
    "    return prune_rates, train_accs, val_accs, wmk_matches, target_matches_empirical, mu_natural_empirical, sigma_natural_empirical\n",
    "\n",
    "def gather_fine_tune_stats(model_path, confidence, ignore_zeros=True, lr=None, lr_scale=None, seeds=[1,2,3,4]):\n",
    "    \"\"\"\n",
    "    Extracts fine-tuning attack results from saved experiment files. Analyzes how fine-tuning attacks degrade watermark detectability over time.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Path to model results directory\n",
    "        confidence (float): Statistical confidence level\n",
    "        ignore_zeros (bool): Whether to exclude zero features from analysis\n",
    "        lr (float): Explicit learning rate used (mutually exclusive with lr_scale)\n",
    "        lr_scale (float): Learning rate as fraction of original (mutually exclusive with lr)\n",
    "        seeds (list): Which experimental seeds to include in analysis\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (epochs, wmk_matches, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, og_trn_accs, new_trn_accs, val_accs)\n",
    "            - epochs: Array of fine-tuning epoch numbers\n",
    "            - wmk_matches: Watermark detection strength over time\n",
    "            - Natural distribution parameters for significance testing\n",
    "            - og_trn_accs: Accuracy on original training data\n",
    "            - new_trn_accs: Accuracy on fine-tuning data\n",
    "            - val_accs: Validation accuracy during fine-tuning\n",
    "    \"\"\"\n",
    "    if lr is not None:\n",
    "        assert lr_scale is None\n",
    "        file = f'results_fine_tune_lr={float(lr)}.txt' if lr is not None else 'results_fine_tune.txt' # if continuation==False else f'results_fine_tune_continuation_from_{starting_epoch}.txt'\n",
    "    elif lr_scale is not None:\n",
    "        assert lr is None\n",
    "        file = f'results_fine_tune_lr_scale={float(lr_scale)}.txt' if lr_scale is not None else 'results_fine_tune.txt' # if continuation==False else f'results_fine_tune_continuation_from_{starting_epoch}.txt'\n",
    "    else:\n",
    "        file = 'results_fine_tune.txt'\n",
    "\n",
    "    dataset_name = model_path.split('training_results')[1].split('/')[1].split('/')[0]\n",
    "    all_wmk_matches = []\n",
    "    seeds_ = [path.split('seed')[1] for path in os.listdir(model_path) if path[0]!='.' and 'png' not in path]# and int(path.split('seed')[1]) in seeds]\n",
    "    if seeds is not None and not seeds_:\n",
    "        seeds_ = [s for s in seeds_ if int(s) in seeds]\n",
    "\n",
    "    all_target_matches_empirical = []\n",
    "    all_mu_natural_empirical = []\n",
    "    all_sigma_natural_empirical = []\n",
    "    og_trn_accs = []\n",
    "    new_trn_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "\n",
    "    for seed in seeds_:\n",
    "        full_path = os.path.join(model_path,f'seed{seed}',file)\n",
    "        with open(full_path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        epochs = [int(l.split('Epoch:')[1].split(',')[0].split()[0]) for l in lines]\n",
    "        if ignore_zeros==True:\n",
    "            l1 = [int(l.split('#_match_wmk w/wout 0s =')[1].split(', confidence')[0].split()[0][1:-1].split(',')[1]) for l in lines]\n",
    "            all_wmk_matches.append(l1)\n",
    "        elif ignore_zeros==False:\n",
    "            l1=[int(l.split('#_match_wmk w/wout 0s =')[1].split(', confidence')[0].split()[0][1:-1].split(',')[0]) for l in lines]\n",
    "            all_wmk_matches.append(l1)\n",
    "\n",
    "        og_trn_accs.append([float(l.split('train (og) acc = ')[1].split(',')[0]) for l in lines])\n",
    "        new_trn_accs.append([float(l.split('train (fine-tune) acc = ')[1].split(',')[0]) for l in lines])\n",
    "        val_accs.append([float(l.split('val acc = ')[1].split(',')[0]) for l in lines])\n",
    "\n",
    "\n",
    "        mu_natural_empirical = float(''.join(open(os.path.join(model_path,f'seed{seed}','distribution.txt')).readlines()).split('mu_natural=')[1].split(',')[0])\n",
    "        sigma_natural_empirical = float(''.join(open(os.path.join(model_path,f'seed{seed}','distribution.txt')).readlines()).split('sigma_natural=')[1].split(',')[0])\n",
    "        z_t = norm.ppf(confidence)\n",
    "        all_mu_natural_empirical.append(mu_natural_empirical)\n",
    "        all_sigma_natural_empirical.append(sigma_natural_empirical)       \n",
    "        target_matches_empirical = np.ceil(min(mu_natural_empirical +z_t*sigma_natural_empirical,config.dataset_attributes[dataset_name]['num_features']))\n",
    "        all_target_matches_empirical.append(target_matches_empirical) \n",
    "\n",
    "    wmk_matches = torch.mean(torch.vstack([torch.tensor(l) for l in all_wmk_matches]),dtype=float,dim=0)\n",
    "    mu_natural_empirical = int(np.round(np.mean(all_mu_natural_empirical)))\n",
    "    sigma_natural_empirical = int(np.round(np.mean(all_sigma_natural_empirical)))\n",
    "    target_matches_empirical = int(np.round(np.mean(all_target_matches_empirical)))\n",
    "    og_trn_accs = torch.mean(torch.vstack([torch.tensor(l) for l in og_trn_accs]),dtype=float,dim=0)\n",
    "    new_trn_accs = torch.mean(torch.vstack([torch.tensor(l) for l in new_trn_accs]),dtype=float,dim=0)\n",
    "    val_accs = torch.mean(torch.vstack([torch.tensor(l) for l in val_accs]),dtype=float,dim=0)\n",
    "\n",
    "    return epochs, wmk_matches, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, og_trn_accs, new_trn_accs, val_accs\n",
    "\n",
    "\n",
    "def arrow(ax, target_matches):\n",
    "    x_start = 0.05\n",
    "    trans = transforms.blended_transform_factory(ax.transAxes,ax.transAxes)\n",
    "    if target_matches > ax.get_ylim()[1]:\n",
    "        y_start  = 0.85#y_ub-0.1\n",
    "        dy = 0.05\n",
    "    elif target_matches < ax.get_ylim()[0]: \n",
    "        y_start = 0.15#y_lb+0.1\n",
    "        dy = -0.05\n",
    "    arrow = patches.FancyArrow(x_start, y_start, 0, dy, transform=trans,  color='r', width=0.02,  head_width=0.05, head_length=0.06)\n",
    "    ax.add_patch(arrow)\n",
    "\n",
    "\n",
    "\n",
    "def arrow_off_plot(ax, curve):\n",
    "    x_start = 0.05\n",
    "    trans = transforms.blended_transform_factory(ax.transAxes,ax.transAxes)\n",
    "    if sum([c > ax.get_ylim()[1] for c in curve])==len(curve):\n",
    "        y_start  = 0.85\n",
    "        dy = 0.05\n",
    "        arrow = patches.FancyArrow(x_start, y_start, 0, dy, transform=trans,  color='r', width=0.02,  head_width=0.05, head_length=0.06)\n",
    "        ax.add_patch(arrow)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def prune_plot(prune_rates, train_accs, val_accs, wmk_matches, c, mu_natural, sigma_natural, target_matches, axs=None,\n",
    "               xlabelsize=8, xticksize=8,yticksize=8,ylabelsize=8,bigtitlesize=13,smalltitlesize=11, ablation=False, ablation_value=None, ablation_color='blue', dataset_name='<insert_dataset_name_here>'):\n",
    "    \"\"\"\n",
    "    Creates publication-ready plots showing watermark persistence under pruning attacks.\n",
    "    \n",
    "    Args:\n",
    "        prune_rates (array): X-axis values (pruning percentages)\n",
    "        train_accs, val_accs (array): Training/validation accuracy curves\n",
    "        wmk_matches (array): Watermark match counts at each pruning level\n",
    "        c (int): Number of subgraphs (for title)\n",
    "        mu_natural, sigma_natural (float): Natural distribution parameters\n",
    "        target_matches (float): Significance threshold for detection\n",
    "        axs (list): Optional pre-created subplot axes\n",
    "        **style_kwargs: Font sizes and styling parameters\n",
    "    \n",
    "    Output: Subplot showing how pruning affects both accuracy and watermark detectability\n",
    "    \n",
    "    Note: Converts raw match counts to p-values for intuitive interpretation\n",
    "    \"\"\"\n",
    "    exclude_accuracies = True if len(axs)==1 else False\n",
    "    if ablation==True:\n",
    "        assert ablation_value is not None\n",
    "\n",
    "    def scale_y1_to_pvalue(y1_value, mu_natural, sigma_natural):\n",
    "        z_score = (y1_value - mu_natural)/sigma_natural\n",
    "        p_value = 1-stats.norm.cdf(z_score)\n",
    "        return p_value\n",
    "\n",
    "\n",
    "    if exclude_accuracies==True:\n",
    "        if axs is None:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(3, 4))\n",
    "            pval_ax = ax\n",
    "        else:\n",
    "            fig = None\n",
    "            pval_ax = axs[0]\n",
    "\n",
    "    elif exclude_accuracies==False:\n",
    "        if axs is None:\n",
    "            fig, axs = plt.subplots(2, 1, figsize=(3, 4))\n",
    "            acc_ax = axs[0]\n",
    "            pval_ax = axs[1]\n",
    "        else:\n",
    "            fig = None\n",
    "            acc_ax, pval_ax = axs[0], axs[1]\n",
    "    target_matches=0.95\n",
    "    wmk_matches = torch.tensor([scale_y1_to_pvalue(num_matches, mu_natural, sigma_natural) for num_matches in wmk_matches])\n",
    "\n",
    "    if exclude_accuracies==False:\n",
    "        if ablation==True:\n",
    "            acc_ax.plot(prune_rates, val_accs, label='Test Acc',color=ablation_color,linestyle='solid') # switch names of \"test\" and \"validation\" for paper results\n",
    "        else:\n",
    "            acc_ax.plot(prune_rates, train_accs, label='Train Acc',color='blue',linestyle='solid')\n",
    "            acc_ax.plot(prune_rates, val_accs, label='Test Acc',color='blue',linestyle='dotted') # switch names of \"test\" and \"validation\" for paper results\n",
    "\n",
    "    label=ablation_value if ablation==True else 'MI $p$-value'\n",
    "    pval_curve_color = 'green' if ablation==False else ablation_color\n",
    "    pval_ax.plot(prune_rates, wmk_matches, label=label,color=pval_curve_color)\n",
    "    x_lb = -0.05\n",
    "    x_ub = max(prune_rates)#0.95\n",
    "\n",
    "\n",
    "    y_min = int(np.floor(torch.min(wmk_matches).item()))\n",
    "    y_max = int(np.ceil(torch.max(wmk_matches).item()))\n",
    "    if target_matches >= y_min and target_matches <= y_max:\n",
    "        pval_ax.axhline(target_matches, color='red',linestyle=':',linewidth=1)\n",
    "        pval_ax.axhline(0,linewidth=0.3,color='gray')\n",
    "        pval_ax.axhline(0.01,linewidth=0.3,color='gray')\n",
    "        pval_ax.axhline(0.05,linewidth=0.3,color='gray')\n",
    "        pval_ax.axhline(0.1,linewidth=0.3,color='gray')\n",
    "        pval_ax.axhline(0.2,linewidth=0.3,color='gray')\n",
    "    else:\n",
    "        arrow(pval_ax, target_matches)\n",
    "        y_text_pos = y_min+0.9*(y_max-y_min) if target_matches>y_min else y_min+0.1*(y_max-y_min)\n",
    "        x_text_pos = x_lb+0.1*(x_ub-x_lb)\n",
    "        pval_ax.text(x_text_pos,y_text_pos, f'Target # Matches = {int(target_matches)}')\n",
    "\n",
    "\n",
    "    if fig:    \n",
    "        fig.suptitle('Effect of Model Pruning on Performance',y=1.01, fontsize=bigtitlesize)\n",
    "        fig.text(0.5, 0.9, f'(\"{dataset_name.capitalize()}\", {c} Subgraphs)', ha='center', fontsize=smalltitlesize)\n",
    "    if len(prune_rates)>20:\n",
    "        prune_rate_xticks = prune_rates[:-1][::10]\n",
    "    else:\n",
    "        prune_rate_xticks = prune_rates[:-1]\n",
    "\n",
    "    if exclude_accuracies==False:\n",
    "        accuracy_yticks = [0,0.2,0.4,0.6,0.7,0.8,1]\n",
    "        acc_ax.set_ylim(0,1.01)\n",
    "        y_lb = acc_ax.get_ylim()[0]\n",
    "        y_lb_index = accuracy_yticks.index(y_lb)\n",
    "        accuracy_yticks = accuracy_yticks[y_lb_index+1:]\n",
    "        acc_ax.set_yticks(accuracy_yticks)\n",
    "        acc_ax.set_xlabel('Prune Rate',fontsize=xlabelsize)\n",
    "        acc_y_label='Accuracy' if ablation==False else 'Test Acc' # switch names of \"test\" and \"validation\" for paper results\n",
    "        acc_ax.set_ylabel(acc_y_label,fontsize=ylabelsize)\n",
    "        acc_ax.set_xlim(-0.05,x_ub)\n",
    "        acc_ax.set_xticks(prune_rate_xticks)\n",
    "        acc_ax.set_xticklabels(prune_rate_xticks,fontsize=xticksize)\n",
    "        acc_ax.set_yticks(accuracy_yticks)\n",
    "        acc_ax.set_yticklabels(accuracy_yticks,fontsize=yticksize)\n",
    "\n",
    "    p_val_yticks = [0.01,0.05,0.1,0.2]\n",
    "    pval_ax.set_xlabel('Prune Rate',fontsize=xlabelsize)\n",
    "    pval_ax.set_ylabel('$p$-value',fontsize=ylabelsize)\n",
    "    pval_ax.set_xlim(x_lb, x_ub)\n",
    "    pval_ax.set_ylim(-0.01,0.21)\n",
    "    pval_ax.set_xticks(prune_rate_xticks)\n",
    "    pval_ax.set_xticklabels(prune_rate_xticks,fontsize=xticksize)\n",
    "    pval_ax.set_yticks(p_val_yticks)\n",
    "    pval_ax.set_yticklabels(p_val_yticks,fontsize=yticksize)\n",
    "    val_off_plot = arrow_off_plot(pval_ax, wmk_matches)\n",
    "    return val_off_plot\n",
    "\n",
    "def fine_tune_plot(dataset_name, epochs, wmk_matches, c, mu_natural, sigma_natural, target_matches, og_trn_accs, new_trn_accs, val_accs, model_path, axs=None,\n",
    "                   xlabelsize=8, xticksize=8,yticksize=8,ylabelsize=8,bigtitlesize=13,smalltitlesize=11, ablation=False, ablation_value=None, ablation_color='blue'):\n",
    "    \"\"\"\n",
    "    Creates plots showing watermark degradation during fine-tuning attacks.\n",
    "    \n",
    "    Args:\n",
    "        dataset_name (str): Dataset name for plot title\n",
    "        epochs (array): X-axis values (fine-tuning epoch numbers)\n",
    "        wmk_matches (array): Watermark detection strength over time\n",
    "        c (int): Number of subgraphs used\n",
    "        mu_natural, sigma_natural (float): Baseline distribution parameters\n",
    "        target_matches (float): Statistical significance threshold\n",
    "        og_trn_accs (array): Accuracy on original training data over time\n",
    "        new_trn_accs (array): Accuracy on new fine-tuning data\n",
    "        val_accs (array): Validation accuracy during fine-tuning\n",
    "        model_path (str): Path for saving plot\n",
    "        axs (list): Optional pre-created axes\n",
    "    \"\"\"\n",
    "    print('mu_natural, sig_natural:',mu_natural, sigma_natural)\n",
    "    def scale_y1_to_pvalue(y1_value, mu_natural, sigma_natural):\n",
    "        z_score = (y1_value - mu_natural)/sigma_natural\n",
    "        p_value = 1-stats.norm.cdf(z_score)\n",
    "        return p_value\n",
    "\n",
    "    exclude_accuracies=True if len(axs)==1 else False\n",
    "    target_matches=0.95\n",
    "    print('num_matches:',wmk_matches)\n",
    "    wmk_matches = torch.tensor([scale_y1_to_pvalue(num_matches, mu_natural, sigma_natural) for num_matches in wmk_matches])\n",
    "\n",
    "    if ablation==True:\n",
    "        assert ablation_value is not None\n",
    "        label=ablation_value\n",
    "    elif ablation==False:\n",
    "        label='MI $p$-value'\n",
    "    \n",
    "    if exclude_accuracies==True:\n",
    "        if axs is None:\n",
    "            fig, ax = plt.subplots(2, 1, figsize=(3, 4))\n",
    "            pval_ax = ax\n",
    "        else:\n",
    "            fig=None\n",
    "            pval_ax = axs[0]\n",
    "    elif exclude_accuracies==False:\n",
    "        if axs is None:\n",
    "            fig, axs = plt.subplots(2, 1, figsize=(3, 4))\n",
    "            acc_ax = axs[0]\n",
    "            pval_ax = axs[1]\n",
    "        else:\n",
    "            fig = None\n",
    "            acc_ax, pval_ax = axs[0], axs[1]\n",
    "\n",
    "    if exclude_accuracies==False:\n",
    "        if ablation==False:\n",
    "            acc_ax.plot(epochs, new_trn_accs, label='Train Acc (New Data)',color='blue',linestyle='solid') \n",
    "            acc_ax.plot(epochs, og_trn_accs, label='Train Acc (Original Data)',color='blue',linestyle='dashed') \n",
    "            acc_ax.plot(epochs, val_accs, label='Test Acc',color='blue',linestyle='dotted') # switch names of \"test\" and \"validation\" for paper results\n",
    "        else:\n",
    "            acc_ax.plot(epochs, val_accs, label='Test Acc',color=ablation_color,linestyle='solid')  # switch names of \"test\" and \"validation\" for paper results\n",
    "\n",
    "    pval_curve_color = ablation_color if ablation==True else 'green'\n",
    "    pval_ax.plot(epochs, wmk_matches, label=label,color=pval_curve_color)\n",
    "\n",
    "    x_lb = 0\n",
    "    x_ub = epochs[-1]+1\n",
    "    y_min = int(np.floor(torch.min(wmk_matches).item()))\n",
    "    y_max = int(np.ceil(torch.max(wmk_matches).item()))\n",
    "    if target_matches >= y_min and target_matches <= y_max:\n",
    "        pval_ax.axhline(0,linewidth=0.3,color='gray')\n",
    "        pval_ax.axhline(0.01,linewidth=0.3,color='gray')\n",
    "        pval_ax.axhline(0.05,linewidth=0.3,color='gray')\n",
    "        pval_ax.axhline(0.1,linewidth=0.3,color='gray')\n",
    "        pval_ax.axhline(0.2,linewidth=0.3,color='gray')\n",
    "    else:\n",
    "        arrow(pval_ax, target_matches)\n",
    "        y_text_pos = y_min+0.9*(y_max-y_min) if target_matches>y_min else y_min+0.1*(y_max-y_min)\n",
    "        x_text_pos = x_lb+0.1*(x_ub-x_lb)\n",
    "        pval_ax.text(x_text_pos,y_text_pos, f'Target # Matches = {int(target_matches)}')\n",
    "    if fig:\n",
    "        fig.suptitle('Effect of Model Fine-Tuning on Performance',y=1.01, fontsize=bigtitlesize)\n",
    "        fig.text(0.5, 0.9, f'(\"{dataset_name.capitalize()}\", {c} Subgraphs)', ha='center', fontsize=smalltitlesize)\n",
    "        image_path = os.path.join(model_path,'fine_tuning_plot.png')\n",
    "        plt.savefig(image_path)\n",
    "        plt.show()\n",
    "\n",
    "    epoch_xticks = [0,10,20,30,40]\n",
    "\n",
    "    if exclude_accuracies==False:\n",
    "        acc_ax.set_xlabel('Fine-Tuning Epoch',fontsize=xlabelsize)\n",
    "        acc_y_label='Accuracy' if ablation==False else 'Test Acc' # switch names of \"test\" and \"validation\" for paper results\n",
    "        acc_ax.set_ylabel(acc_y_label,fontsize=ylabelsize)\n",
    "        acc_ax.set_ylim(0.7,1.01)\n",
    "        accuracy_yticks = [0.4,0.5,0.6,0.7,0.75,0.8,0.85,0.9,0.95,1.00]\n",
    "        y_lb = acc_ax.get_ylim()[0]\n",
    "        y_lb_index = accuracy_yticks.index(y_lb)\n",
    "        accuracy_yticks = accuracy_yticks[y_lb_index+1:]\n",
    "        acc_ax.set_yticks(accuracy_yticks)\n",
    "        acc_ax.set_xlim(x_lb, x_ub)\n",
    "        acc_ax.set_yticklabels(accuracy_yticks,fontsize=yticksize)\n",
    "        acc_ax.set_xticks(epoch_xticks)\n",
    "\n",
    "    p_val_yticks = [0.01,0.05,0.1,0.2]\n",
    "    pval_ax.set_xlabel('Fine-Tuning Epoch',fontsize=xlabelsize)\n",
    "    pval_ax.set_ylabel('$p$-value',fontsize=ylabelsize)\n",
    "    pval_ax.set_xlim(x_lb, x_ub)\n",
    "    pval_ax.set_ylim(-0.01,0.21)\n",
    "    pval_ax.set_yticks(p_val_yticks)\n",
    "    pval_ax.set_yticklabels(p_val_yticks,fontsize=yticksize)\n",
    "    pval_ax.set_xticks(epoch_xticks)\n",
    "    pval_ax.set_xticklabels(epoch_xticks,fontsize=xticksize)\n",
    "    val_off_plot = arrow_off_plot(pval_ax, wmk_matches)\n",
    "    return val_off_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc20e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_num_subgraphs_from_path(s):\n",
    "    # For example, return the length of each string\n",
    "    return int(s.split('numSubgraphs')[1].split('_')[0])\n",
    "\n",
    "def parse_subgraph_size(f):\n",
    "    return float(f.split('fraction')[1].split('_')[0])\n",
    "\n",
    "\n",
    "def plot_all_datasets_ablation(dataset_architecture_dict, variable='subgraph_size',task='prune',pruning_type='unstructured', arch='SAGE',exclude_title=False, include_accs=False,show_subgraph_sizes='all',\n",
    "                              xrotation=45,xticksize=7,yticksize=7,xlabelsize=9,ylabelsize=9,bigtitlesize=13,smalltitlesize=11,legendsize=8, lr_scale=0.1, seeds=[0,1,2,3,4], project_dir = ''):\n",
    "    \"\"\"\n",
    "    Creates comprehensive ablation study plots across multiple datasets and conditions.\n",
    "    \n",
    "    Args:\n",
    "        dataset_architecture_dict (dict): Dataset names mapped to architectures\n",
    "        variable (str): Hyperparameter to vary ('subgraph_size' or 'num_subgraph')\n",
    "        task (str): Type of analysis ('prune' or 'fine_tune')\n",
    "        pruning_type (str): Pruning method if task='prune'\n",
    "        arch (str): GNN architecture to analyze\n",
    "        include_accs (bool): Whether to show accuracy plots alongside p-values\n",
    "        **style_kwargs: Detailed styling parameters\n",
    "    \"\"\"\n",
    "\n",
    "    num_cols = len(dataset_architecture_dict)\n",
    "    fig = plt.figure(figsize=(6, 2.5))\n",
    "    gs = gridspec.GridSpec(2, num_cols, figure=fig)\n",
    "    if variable=='subgraph_size':\n",
    "        if show_subgraph_sizes=='all':\n",
    "            subgraph_sizes = [0.001,0.002,0.003,0.004,0.005,0.006,0.007,0.008,0.009,0.01]\n",
    "        elif show_subgraph_sizes=='evens':\n",
    "            subgraph_sizes = [0.002,0.004,0.006,0.008,0.01]\n",
    "        elif show_subgraph_sizes=='odds':\n",
    "            subgraph_sizes = [0.001,0.003,0.005,0.007,0.009]\n",
    "    num_subgraphs = [2,3,4,5]\n",
    "    subgraph_size=0.005\n",
    "    num_subgraph=4\n",
    "    value_list = subgraph_sizes if variable=='subgraph_size' else num_subgraphs\n",
    "    color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    for i, dataset_name in enumerate(dataset_architecture_dict.keys()):\n",
    "\n",
    "        training_results_folder = f'{project_dir}/training_results/{dataset_name}'\n",
    "        architecture_folder = [os.path.join(training_results_folder,f) for f in os.listdir(training_results_folder) if f[0]!='.' and 'clf' not in f and 'watermark' not in f and 'KD' not in f and arch in f][0]\n",
    "        model_folders = [f for f in os.listdir(architecture_folder) if f[0]!='.']\n",
    "        confidence = 0.95\n",
    "        col = i\n",
    "        if include_accs==False:\n",
    "            pval_ax = fig.add_subplot(gs[0,col])\n",
    "            axs = [pval_ax]\n",
    "        if include_accs==True:\n",
    "            acc_ax = fig.add_subplot(gs[0,col])\n",
    "            pval_ax = fig.add_subplot(gs[1,col])\n",
    "            axs = [acc_ax, pval_ax]\n",
    "\n",
    "        \n",
    "        off_plot_vals = []\n",
    "        for j, value in enumerate(value_list):\n",
    "            if variable=='subgraph_size':\n",
    "                subgraph_size=value\n",
    "            elif variable=='num_subgraph':\n",
    "                num_subgraph=value\n",
    "\n",
    "            ablation_color = color_cycle[j]\n",
    "            print(f\"looking for model folder with subgraph_size={subgraph_size} and num_subgraph={num_subgraph}\")\n",
    "            model_folder = [os.path.join(architecture_folder,f) for f in model_folders if parse_subgraph_size(f)==subgraph_size and parse_num_subgraphs_from_path(f)==num_subgraph][0]\n",
    "            c = int(model_folder.split('numSubgraphs')[1].split('_')[0])\n",
    "\n",
    "\n",
    "            if task=='prune':\n",
    "                prune_rates, train_accs, val_accs, wmk_matches, target_matches_empirical, mu_natural_empirical, sigma_natural_empirical = gather_prune_stats(model_folder, confidence,pruning_type=pruning_type)\n",
    "                val_off_plot = prune_plot(prune_rates, train_accs, val_accs, wmk_matches, c, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, axs=axs,\n",
    "                        xlabelsize=xlabelsize, xticksize=xticksize,yticksize=yticksize,ylabelsize=ylabelsize,bigtitlesize=bigtitlesize,smalltitlesize=smalltitlesize, ablation=True, ablation_value=value, ablation_color=ablation_color)\n",
    "                if val_off_plot==True:\n",
    "                    off_plot_vals.append(value)\n",
    "\n",
    "            elif task=='fine_tune':\n",
    "                epochs, wmk_matches, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, og_trn_accs, new_trn_accs, val_accs = gather_fine_tune_stats(model_folder, confidence, ignore_zeros=True, lr_scale=lr_scale, seeds=seeds)#, continuation=continuation,starting_epoch=starting_epoch)\n",
    "                val_off_plot= fine_tune_plot(dataset_name, epochs, wmk_matches, c, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, og_trn_accs, new_trn_accs, val_accs, model_folder, axs=axs,\n",
    "                            xlabelsize=xlabelsize, xticksize=xticksize,yticksize=yticksize,ylabelsize=ylabelsize,bigtitlesize=bigtitlesize,smalltitlesize=smalltitlesize, ablation=True, ablation_value=value, ablation_color=ablation_color)\n",
    "                if val_off_plot==True:\n",
    "                    off_plot_vals.append(value)\n",
    "\n",
    "            if task=='prune':\n",
    "                if pruning_type=='unstructured':\n",
    "                    xticks = np.linspace(0,1,6)[:-1]\n",
    "                    xticklabels = [f'{v:.2f}' for v in xticks]\n",
    "                    x_lb,x_ub = -0.01,1.01\n",
    "                elif pruning_type=='structured':\n",
    "                    xticks = np.linspace(0,0.5,6)[:-1]\n",
    "                    xticklabels = [f'{v:.2f}' for v in xticks]\n",
    "                    x_lb,x_ub = -0.01,0.501\n",
    "            elif task=='fine_tune':\n",
    "                xticks = xticklabels = [int(i) for i in np.linspace(0,50,6)[:-1]]\n",
    "                x_lb,x_ub = -1,51\n",
    "\n",
    "            pval_ax.set_label(value)\n",
    "            if include_accs==True:\n",
    "                acc_ax.set_title(f'Photo' if dataset_name=='photo' else f'{dataset_name}',fontsize=smalltitlesize)\n",
    "            else:\n",
    "                pval_ax.set_title(f'Photo' if dataset_name=='photo' else f'{dataset_name}',fontsize=smalltitlesize)\n",
    "            pval_ax.set_xticks(xticks)\n",
    "            pval_ax.set_xticklabels(xticklabels,rotation=xrotation,fontsize=xticksize)\n",
    "            pval_ax.set_xlim(x_lb,x_ub)\n",
    "        if i==0:\n",
    "            handles_1_, labels_1_ = [],[]\n",
    "            handles_1, labels_1 = pval_ax.get_legend_handles_labels()\n",
    "            handles_1_.extend(handles_1)\n",
    "            labels_1_.extend(labels_1)\n",
    "            if include_accs==True:\n",
    "                handles_0_, labels_0_ = [],[]\n",
    "                handles_0, labels_0 = acc_ax.get_legend_handles_labels()\n",
    "                handles_0_.extend(handles_0)\n",
    "                labels_0_.extend(labels_0)\n",
    "\n",
    "        pval_ax.label_outer()\n",
    "        if include_accs==True:\n",
    "            acc_ax.label_outer()\n",
    "        if len(off_plot_vals)>0:\n",
    "            x_text_loc = 0.05 if task=='prune' else 5\n",
    "            var_letter = \"$s$\" if variable=='subgraph_size' else \"$c$\"\n",
    "            pval_ax.text(x_text_loc,0.90*0.2,f\"{var_letter} = {','.join([str(v) for v in off_plot_vals])}\",bbox=dict(facecolor='lightgray', alpha=0.7,edgecolor='none',pad=0.1),color='black')\n",
    "\n",
    "    if exclude_title==False:\n",
    "        if task=='prune':\n",
    "            if pruning_type=='unstructured':\n",
    "                fig.suptitle(f'{pruning_type.capitalize()} Pruning',y=1.02,fontsize=bigtitlesize)\n",
    "            else:\n",
    "                fig.suptitle(f'Pruning',y=1.02,fontsize=bigtitlesize)\n",
    "        elif task=='fine_tune':\n",
    "            fig.suptitle('Fine Tuning',y=1.02,fontsize=bigtitlesize)\n",
    "    task_descrip = f'{pruning_type}_pruning' if task=='prune' else 'fine_tuning'\n",
    "    image_name = f'all_datasets_{arch}_{task_descrip}_ablation_{variable}'\n",
    "    ncols_legend=4 if variable=='subraph_size' else 5\n",
    "    ylegend=-0.15 if task=='prune' else -0.15\n",
    "    legend_title = 'Number Watermarked Subgraphs ($T$)' if variable=='num_subgraph' else 'Watermarked Subgraph Size ($s$)'\n",
    "    fig.legend(handles=handles_1_,labels=labels_1_,ncols=ncols_legend, loc='center', bbox_to_anchor=(0.5,ylegend),fontsize=legendsize,title=legend_title)\n",
    "    fig.subplots_adjust(wspace=0.0,hspace=0.0)\n",
    "\n",
    "    plt.savefig(f'{project_dir}/{image_name}.png',bbox_inches='tight',dpi=300)\n",
    "\n",
    "\n",
    "def plot_all_datasets(dataset_architecture_dict, num_subgraphs, subgraph_size, task='prune',pruning_type='unstructured', arch='SAGE',exclude_title=False,\n",
    "                              xrotation=45,xticksize=7,yticksize=7,xlabelsize=9,ylabelsize=9,bigtitlesize=13,smalltitlesize=11,legendsize=8, lr=None, lr_scale=None, seeds=[1,2,3,4], projet_dir=''):\n",
    "    \"\"\"\n",
    "    Creates standardized comparison plots across datasets for fixed hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "        dataset_architecture_dict (dict): Dataset configurations\n",
    "        num_subgraphs (int): Fixed number of watermarked subgraphs\n",
    "        subgraph_size (float): Fixed subgraph size fraction\n",
    "        task (str): Analysis type ('prune' or 'fine_tune')\n",
    "        **kwargs: Additional parameters (learning rates, styling, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    if lr is not None:\n",
    "        assert lr_scale is None\n",
    "    if lr_scale is not None:\n",
    "        assert lr is None\n",
    "\n",
    "    num_cols = len(dataset_architecture_dict)\n",
    "    fig = plt.figure(figsize=(6, 2.5))\n",
    "    gs = gridspec.GridSpec(2, num_cols, figure=fig)\n",
    "    for i, dataset_name in enumerate(dataset_architecture_dict.keys()):\n",
    "        print(dataset_name,arch, num_subgraphs, subgraph_size)\n",
    "        training_results_folder = f'{project_dir}/training_results/{dataset_name}'\n",
    "        architecture_folder = [os.path.join(training_results_folder,f) for f in os.listdir(training_results_folder) if f[0]!='.' and 'clf' not in f and 'watermark' not in f and 'KD' not in f and arch in f][0]\n",
    "        model_folders = [f for f in os.listdir(architecture_folder) if f[0]!='.']\n",
    "        print(f\"looking for model with subgraph_size={subgraph_size} and num_subgraphs={num_subgraphs}\")\n",
    "        model_folder = [os.path.join(architecture_folder,f) for f in model_folders if parse_subgraph_size(f)==subgraph_size and parse_num_subgraphs_from_path(f)==num_subgraphs][0]\n",
    "        col = i\n",
    "        ax1 = fig.add_subplot(gs[0,col])\n",
    "        ax2 = fig.add_subplot(gs[1,col])\n",
    "        c = int(model_folder.split('numSubgraphs')[1].split('_')[0])\n",
    "        confidence = 0.95\n",
    "        if task=='prune':\n",
    "            prune_rates, train_accs, val_accs, wmk_matches, target_matches_empirical, mu_natural_empirical, sigma_natural_empirical = gather_prune_stats(model_folder, confidence,pruning_type=pruning_type)\n",
    "            prune_plot(prune_rates, train_accs, val_accs, wmk_matches, c, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, axs=[ax1,ax2],\n",
    "                       xlabelsize=xlabelsize, xticksize=xticksize,yticksize=yticksize,ylabelsize=ylabelsize,bigtitlesize=bigtitlesize,smalltitlesize=smalltitlesize)\n",
    "\n",
    "        elif task=='fine_tune':\n",
    "            epochs, wmk_matches, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, og_trn_accs, new_trn_accs, val_accs = gather_fine_tune_stats(model_folder, confidence, ignore_zeros=True, lr=lr, lr_scale=lr_scale, seeds=seeds)#, continuation=continuation,starting_epoch=starting_epoch)\n",
    "            fine_tune_plot(dataset_name, epochs, wmk_matches, c, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, og_trn_accs, new_trn_accs, val_accs, model_folder, axs=[ax1, ax2],\n",
    "                           xlabelsize=xlabelsize, xticksize=xticksize,yticksize=yticksize,ylabelsize=ylabelsize,bigtitlesize=bigtitlesize,smalltitlesize=smalltitlesize)\n",
    "            fig.suptitle(f'Learning Rate Scale: {lr_scale}',y=1.05)\n",
    "            \n",
    "        if task=='prune':\n",
    "            if pruning_type=='unstructured':\n",
    "                xticks = np.linspace(0,1,6)[:-1]\n",
    "                xticklabels = [f'{v:.2f}' for v in xticks]\n",
    "                x_lb,x_ub = -0.01,1.01\n",
    "            elif pruning_type=='structured':\n",
    "                xticks = np.linspace(0,0.5,6)[:-1]\n",
    "                xticklabels = [f'{v:.2f}' for v in xticks]\n",
    "                x_lb,x_ub = -0.01,0.501\n",
    "        elif task=='fine_tune':\n",
    "            xticks = xticklabels = [int(i) for i in np.linspace(0,50,6)[:-1]]\n",
    "            x_lb,x_ub = -1,51\n",
    "\n",
    "        ax1.set_title(f'Photo ({arch})' if dataset_name=='photo' else f'{dataset_name} ({arch})',fontsize=smalltitlesize)\n",
    "        ax1.label_outer()\n",
    "        ax2.label_outer()\n",
    "        handles, labels = [],[]\n",
    "        handles_0, labels_0 = ax1.get_legend_handles_labels()\n",
    "        handles_1, labels_1 = ax2.get_legend_handles_labels()\n",
    "        handles.extend(handles_0);  handles.extend(handles_1)\n",
    "        labels.extend(labels_0);    labels.extend(labels_1)\n",
    "        ax1.set_xticks(xticks)\n",
    "        ax1.set_xlim(x_lb,x_ub)\n",
    "        ax2.set_xticks(xticks)\n",
    "        ax2.set_xticklabels(xticklabels,rotation=xrotation,fontsize=xticksize)\n",
    "        ax2.set_xlim(x_lb,x_ub)\n",
    "\n",
    "    if exclude_title==False:\n",
    "        if task=='prune':\n",
    "            if pruning_type=='unstructured':\n",
    "                fig.suptitle(f'{pruning_type.capitalize()} Pruning',y=1.01,fontsize=bigtitlesize)\n",
    "            else:\n",
    "                fig.suptitle(f'Pruning',y=1.02,fontsize=bigtitlesize)\n",
    "        elif task=='fine_tune':\n",
    "            fig.suptitle('Fine Tuning',y=1.02,fontsize=bigtitlesize)\n",
    "    task_descrip = f'{pruning_type}_pruning' if task=='prune' else 'fine_tuning'\n",
    "    image_name = f'all_datasets_{arch}_{task_descrip}'\n",
    "    ncols_legend=3 if task=='prune' else 2\n",
    "    ylegend=-0.12 if task=='prune' else -0.15\n",
    "    fig.legend(handles=handles,labels=labels,ncols=ncols_legend, loc='center', bbox_to_anchor=(0.5,ylegend),fontsize=legendsize)\n",
    "    fig.subplots_adjust(wspace=0.0,hspace=0.0)\n",
    "\n",
    "    plt.savefig(f'{projet_dir}/{image_name}.png',bbox_inches='tight',dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "# Example\n",
    "\n",
    "dataset_architecture_dict = {'photo':'SAGE','PubMed':'SAGE','CS':'SAGE'}\n",
    "arch='SAGE'\n",
    "xrotation=0\n",
    "xticksize=9\n",
    "yticksize=9\n",
    "xlabelsize=9\n",
    "ylabelsize=9\n",
    "bigtitlesize=13\n",
    "smalltitlesize=11\n",
    "legendsize=9\n",
    "exclude_title=True\n",
    "\n",
    "plot_all_datasets(dataset_architecture_dict, 4, 0.005,'fine_tune',exclude_title=exclude_title, arch='SGC',xrotation=xrotation,xticksize=xticksize,yticksize=yticksize,\n",
    "                                                                                        xlabelsize=xlabelsize,ylabelsize=ylabelsize,bigtitlesize=bigtitlesize,\n",
    "                                                                                        smalltitlesize=smalltitlesize,legendsize=legendsize, lr_scale=0.1)\n",
    "\n",
    "plot_all_datasets_ablation(dataset_architecture_dict, 'num_subgraph','fine_tune',exclude_title=exclude_title, arch='SAGE',include_accs=True, xrotation=xrotation,xticksize=xticksize,yticksize=yticksize,\n",
    "                                                                                        xlabelsize=xlabelsize,ylabelsize=ylabelsize,bigtitlesize=bigtitlesize,\n",
    "                                                                                        smalltitlesize=smalltitlesize,legendsize=legendsize, seeds=None,project_dir=project_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd65f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_fine_tune_in_grid(arch_path, subgraph_size=None):\n",
    "    model_paths = [os.path.join(arch_path,f) for f in os.listdir(arch_path) if  f[0]!='.' and '.png' not in f and 'ignore' not in f]\n",
    "    if subgraph_size is not None:\n",
    "        model_paths = [m for m in model_paths if parse_subgraph_size(m)==subgraph_size]\n",
    "    model_paths = sorted(model_paths, key=parse_num_subgraphs_from_path)\n",
    "\n",
    "    num_cols = len(model_paths)\n",
    "    fig = plt.figure(figsize=(9, 3))\n",
    "    gs = gridspec.GridSpec(2, num_cols, figure=fig)\n",
    "\n",
    "    for i, model_path in enumerate(model_paths):\n",
    "        col = i\n",
    "        ax1 = fig.add_subplot(gs[0,col])\n",
    "        ax2 = fig.add_subplot(gs[1,col])\n",
    "        dataset_name = model_path.split('training_results')[1].split('/')[1].split('/')[0]\n",
    "        c = int(model_path.split('numSubgraphs')[1].split('_')[0])\n",
    "        confidence = 0.95\n",
    "        epochs, wmk_matches, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, og_trn_accs, new_trn_accs, val_accs = gather_fine_tune_stats(model_path, confidence, ignore_zeros=True, seeds=seeds)#, continuation=continuation,starting_epoch=starting_epoch)\n",
    "        fine_tune_plot(dataset_name, epochs, wmk_matches, c, confidence, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, og_trn_accs, new_trn_accs, val_accs, model_path, axs=[ax1, ax2])\n",
    "        ax1.label_outer()\n",
    "        ax1.set_title(f'{c} Subgraphs',y=0.8,fontsize=8)\n",
    "        ax2.label_outer()\n",
    "\n",
    "        handles, labels = [],[]\n",
    "        handles_0, labels_0 = ax1.get_legend_handles_labels()\n",
    "        handles_1, labels_1 = ax2.get_legend_handles_labels()\n",
    "        handles.extend(handles_0);  handles.extend(handles_1)\n",
    "        labels.extend(labels_0);    labels.extend(labels_1)\n",
    "\n",
    "\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.04), ncol=4,fontsize=8)\n",
    "    fig.suptitle(dataset_name.capitalize(),y=0.9,fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_prune_in_grid(arch_path,pruning_type='structured', subgraph_size=None):\n",
    "    model_paths = [os.path.join(arch_path,f) for f in os.listdir(arch_path) if  f[0]!='.' and '.png' not in f and 'ignore' not in f]\n",
    "    if subgraph_size is not None:\n",
    "        model_paths = [m for m in model_paths if parse_subgraph_size(m)==subgraph_size]\n",
    "    model_paths = sorted(model_paths, key=parse_num_subgraphs_from_path)\n",
    "    num_cols = len(model_paths)\n",
    "    fig = plt.figure(figsize=(9, 3))\n",
    "    gs = gridspec.GridSpec(2, num_cols, figure=fig)\n",
    "\n",
    "    for i, model_path in enumerate(model_paths):\n",
    "        col = i\n",
    "        ax1 = fig.add_subplot(gs[0,col])\n",
    "        ax2 = fig.add_subplot(gs[1,col])\n",
    "        dataset_name = model_path.split('training_results')[1].split('/')[1].split('/')[0]\n",
    "        c = int(model_path.split('numSubgraphs')[1].split('_')[0])\n",
    "        confidence = 0.95\n",
    "        prune_rates, train_accs, val_accs, wmk_matches, target_matches_empirical, mu_natural_empirical, sigma_natural_empirical = gather_prune_stats(model_path, confidence,pruning_type=pruning_type)\n",
    "        prune_plot(prune_rates, train_accs, val_accs, wmk_matches, c, confidence, mu_natural_empirical, sigma_natural_empirical, target_matches_empirical, model_path, use_p_instead_of_count=True, axs=[ax1,ax2])\n",
    "\n",
    "        ax1.label_outer()\n",
    "        ax1.set_title(f'{c} Subgraphs',y=0.8,fontsize=8)\n",
    "        ax2.label_outer()\n",
    "\n",
    "        handles, labels = [],[]\n",
    "        handles_0, labels_0 = ax1.get_legend_handles_labels()\n",
    "        handles_1, labels_1 = ax2.get_legend_handles_labels()\n",
    "        handles.extend(handles_0);  handles.extend(handles_1)\n",
    "        labels.extend(labels_0);    labels.extend(labels_1)\n",
    "\n",
    "\n",
    "    fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.04), ncol=4,fontsize=8)\n",
    "    fig.suptitle(dataset_name.capitalize(),y=0.9,fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "\n",
    "folder = '<main_directory_path>/training_results/photo/archSAGE_elu_nLayers3_hDim256_drop0.1_skipTrue'\n",
    "num_cols = len([f for f in os.listdir(folder) if f[0]!='.' and '.png' not in f and 'ignore' not in f])\n",
    "plot_all_fine_tune_in_grid(folder, subgraph_size=0.005)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watermarking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
